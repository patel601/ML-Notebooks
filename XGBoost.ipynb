{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c996dfe-d036-4686-8924-70b0af14d9a8",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "We will be using the Iris data set. This data set includes the width and length of the petals and sepals of many Iris flowers, and the specific species of Iris the flower belongs to. Our challenge is to predict the species of a flower sample just based on the sizes of its petals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e386e8be-37f7-460c-8376-5b2fffed80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88bb7215-d8b1-4819-9cd6-4b750e03ef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "4\n",
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "numSamples, numFeatures = iris.data.shape\n",
    "print(numSamples)\n",
    "print(numFeatures)\n",
    "print(list(iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e961f5-37c3-4df1-8c69-a3248a89647e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we will divide our data into 20% for testing, and the remaining 80% for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153c50b7-3b73-486e-8d31-7bcf0baba47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2b9221-18b3-4f4f-a187-973d21edff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f1a75-ec4d-402f-a251-21fa6d25122a",
   "metadata": {},
   "source": [
    "\n",
    "Now we will load up XGBoost, and covert our data into the DMattrix format that it expects. One for the training data, and one for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d7a1957-a9fb-47b9-a232-d885b0d2c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7815684-ffa3-4795-9505-9d728d8933a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a0d27-37f8-4e94-945a-a2374141aba2",
   "metadata": {},
   "source": [
    "\n",
    "Now we have to define our hyperparameters. We are choosing softmax since this is a multiple classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e1be7be-3656-4590-bfae-44166051f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 2, # play around with max_depth to see how low it can be\n",
    "    'eta': 0.6,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3\n",
    "}\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6484fb94-00f6-4aa9-8ba2-c959469651a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "329c7a58-9fe1-491a-bc3a-55d9e4a16fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 0. 2. 0. 2. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 2. 1. 0. 0.\n",
      " 2. 0. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1dfc8-d1ac-4c58-93fe-bad5540742f9",
   "metadata": {},
   "source": [
    "### Measuring the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73fbdb39-0b0a-4cf6-88fa-efa3a330f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b328b2b9-7947-46fe-8a5c-843af5c08593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
